  vars:
    NB_CLUSTER_NAME: "nb"
    MLFLOW_CLUSTER_NAME: "mlflow"
    TRAINING_CLUSTER_NAME: "trainingengineinstance"
    AD_USER_NAME: "ad_user1"
    AD_USER_PASS: "pass123"

  - name: configure tenant hpecp
    copy:
      dest: ~/.hpecp_tenant.config
      content: |-
        [default]
        api_host = "{{ gatw_pub_dns }}"
        api_port = 8080
        use_ssl = True
        verify_ssl = False
        warn_ssl = False
        [tenant]
        tenant = "{{ tenant_ns.stdout }}"
        username = "{{ AD_USER_NAME }}"
        password = "{{ AD_USER_PASS }}"
      force: yes

  - set_fact:
      tenant_profile: "PROFILE=tenant HPECP_CONFIG_FILE=~/.hpecp_tenant.conf hpecp tenant k8skubeconfig"
      kubeattenant: "kubectl --kubeconfig ~/.kube/hpecp_tenant.config -n {{ tenant_ns.stdout }}"

  - name: get ad user
    shell: "hpecp user list --query \"[?label.name=='{{ AD_USER_NAME }}'] | [0] | [_links.self.href]\" --output text | cut -d '/' -f 5 | sed '/^$/d'"
    register: ad_user_id_out

  - name: get ad user secret
    shell: "python3 -c \"import hashlib; print(hashlib.md5('{{ ad_user_id_out.stdout }}-{{ AD_USER_NAME }}'.encode('utf-8')).hexdigest())\""
    register: ad_user_secret_out

  - set_fact:
      AD_USER_KC_SECRET: "hpecp-kc-secret-{{ ad_user_secret_out.stdout }}"

  - name: delete existing secret
    shell: "{{ kubeatns }} delete secret {{ AD_USER_KC_SECRET }}"
    ignore_errors: yes

  - name: create ad user secret
    shell: "PROFILE=tenant HPECP_CONFIG_FILE=~/.hpecp_tenant.conf hpecp httpclient post {{ cluster_id.stdout }}/kubectl <(echo -n '{\"data\":\"'{{ DATA_BASE64 }}'\",\"o\p":\"create\"}')"
    vars:
      DATA: |-
        {
          "stringData": {
            # "config": "{{ AD_USER_KUBECONFIG }}"
          },
          "kind": "Secret",
          "apiVersion": "v1",
          "metadata": {
            "labels": {
              "kubedirector.hpe.com/username": "{{ AD_USER_NAME }}",
              "kubedirector.hpe.com/userid": "{{ AD_USER_ID }}",
              "kubedirector.hpe.com/secretType": "kubeconfig"
            },
            "namespace": "{{ tenant_ns.stdout }}",
            "name": "{{ AD_USER_KC_SECRET }}"
          }
        }
      DATA_BASE64: {{ DATA | base64() }}

# ###
# ### Training Cluster
# ###
# echo "Launching Training Cluster"
# cat <<EOF_YAML | kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) -n $TENANT_NS apply -f -
# apiVersion: "kubedirector.hpe.com/v1beta1"
# kind: "KubeDirectorCluster"
# metadata: 
#   name: "$TRAINING_CLUSTER_NAME"
#   namespace: "$TENANT_NS"
#   labels: 
#     description: ""
# spec: 
#   app: "training-engine"
#   namingScheme: "CrNameRole"
#   appCatalog: "local"
#   connections: 
#     secrets: 
#       - $AD_USER_KC_SECRET
#       - hpecp-ext-auth-secret
#   roles: 
#     - 
#       id: "LoadBalancer"
#       members: 1
#       resources: 
#         requests: 
#           cpu: "2"
#           memory: "4Gi"
#           nvidia.com/gpu: "0"
#         limits: 
#           cpu: "2"
#           memory: "4Gi"
#           nvidia.com/gpu: "0"
#       #Note: "if the application is based on hadoop3 e.g. using StreamCapabilities interface, then change the below dtap label to 'hadoop3', otherwise for most applications use the default 'hadoop2'"
#       podLabels: 
#         hpecp.hpe.com/dtap: "hadoop2"
#     - 
#       id: "RESTServer"
#       members: 1
#       resources: 
#         requests: 
#           cpu: "2"
#           memory: "4Gi"
#           nvidia.com/gpu: "0"
#         limits: 
#           cpu: "2"
#           memory: "4Gi"
#           nvidia.com/gpu: "0"
#       #Note: "if the application is based on hadoop3 e.g. using StreamCapabilities interface, then change the below dtap label to 'hadoop3', otherwise for most applications use the default 'hadoop2'"
#       podLabels: 
#         hpecp.hpe.com/dtap: "hadoop2"
#     - 
#       id: "controller"
#       members: 1
#       resources: 
#         requests: 
#           cpu: "2"
#           memory: "4Gi"
#           nvidia.com/gpu: "0"
#         limits: 
#           cpu: "2"
#           memory: "4Gi"
#           nvidia.com/gpu: "0"
#       #Note: "if the application is based on hadoop3 e.g. using StreamCapabilities interface, then change the below dtap label to 'hadoop3', otherwise for most applications use the default 'hadoop2'"
#       podLabels: 
#         hpecp.hpe.com/dtap: "hadoop2"
# EOF_YAML
# date
# echo Waiting for Training to have state==configured
  
#   COUNTER=0
#   while [ \$COUNTER -lt 30 ]; 
#   do
#     STATE=\$(kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#                 get kubedirectorcluster -n $TENANT_NS $TRAINING_CLUSTER_NAME -o 'jsonpath={.status.state}')
#     echo STATE=\$STATE
#     [[ \$STATE == "configured" ]] && break
#     sleep 1m
#     let COUNTER=COUNTER+1 
#   done
#   date
# ###
# ### Jupyter Notebook
# ###
# export AD_USER_ID=$AD_USER_ID
# echo "Launching Jupyter Notebook as '$AD_USER_NAME' user ($AD_USER_ID)"
# cat <<EOF_YAML | kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) -n $TENANT_NS apply -f -
# apiVersion: "kubedirector.hpe.com/v1beta1"
# kind: "KubeDirectorCluster"
# metadata: 
#   name: "$NB_CLUSTER_NAME"
#   namespace: "$TENANT_NS"
#   labels: 
#     "kubedirector.hpe.com/createdBy": "$AD_USER_ID"
# spec: 
#   app: "jupyter-notebook"
#   appCatalog: "local"
#   connections:
#     clusters:
#       - $MLFLOW_CLUSTER_NAME
#       - $TRAINING_CLUSTER_NAME
#     secrets: 
#       - hpecp-sc-secret-gitea-ad-user1-nb
#       - hpecp-ext-auth-secret
#       - mlflow-sc
#       - $AD_USER_KC_SECRET
#   roles: 
#     - 
#       id: "controller"
#       members: 1
#       serviceAccountName: "ecp-tenant-member-sa"
#       resources: 
#         requests: 
#           cpu: "2"
#           memory: "4Gi"
#           nvidia.com/gpu: "0"
#         limits: 
#           cpu: "2"
#           memory: "4Gi"
#           nvidia.com/gpu: "0"
#       storage: 
#         # size: "20Gi"
#         # storageClassName: "dfdemo"
	  
#       #Note: "if the application is based on hadoop3 e.g. using StreamCapabilities interface, then change the below dtap label to 'hadoop3', otherwise for most applications use the default 'hadoop2'"
#       podLabels: 
#         hpecp.hpe.com/dtap: "hadoop2"
# EOF_YAML
# EOF1

# ./bin/ssh_rdp_linux_server.sh rm -rf static/
# ./bin/ssh_rdp_linux_server.sh mkdir static/

# for FILE in $(ls -1 static/*)
# do
#   cat $FILE | ./bin/ssh_rdp_linux_server.sh "cat > $FILE"
# done


# ssh -q -o StrictHostKeyChecking=no -i "${LOCAL_SSH_PRV_KEY_PATH}" -T ubuntu@${RDP_PUB_IP} <<-EOF1
#   set -e
#   set -u 
#   set -o pipefail
#   date
#   echo Waiting for Notebook to have state==configured
  
#   COUNTER=0
#   while [ \$COUNTER -lt 180 ]; 
#   do
#     STATE=\$(kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#                 get kubedirectorcluster -n $TENANT_NS $NB_CLUSTER_NAME -o 'jsonpath={.status.state}')
#     echo STATE=\$STATE
#     [[ \$STATE == "configured" ]] && break
#     sleep 1m
#     let COUNTER=COUNTER+1 
#   done
#   date
  
#   ###########
#   # Retrieve the notebook pod
#   ###########
#   POD=\$(kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#     get pod -l kubedirector.hpe.com/kdcluster=$NB_CLUSTER_NAME -n $TENANT_NS -o 'jsonpath={.items..metadata.name}')
    
#   echo TENANT_NS=$TENANT_NS
#   echo POD=\$POD
  
#   ###########
#   ## Setup notebook service-account-token
#   ###########
  
#   if [[ "$HPECP_VERSION" == *"5.4"*  ]]; then
  
#     set -x
    
#     SECRET_NAME=\$(kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#        get secret -n $TENANT_NS --field-selector type=kubernetes.io/service-account-token | grep '\-sa\-' | cut -f 1 -d' ')
#     echo SECRET_NAME=\$SECRET_NAME
    
#     # Extract and decode
#     kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#         get secret -n $TENANT_NS \$SECRET_NAME -o yaml | grep " token:" | awk '{print \$2}' | base64 -d > token
    
#     # FIXME
    
#     # Put the token file in your nb pod
#     # kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#     #   cp token -c app \$POD:/var/run/secrets/kubernetes.io/serviceaccount/token -n $TENANT_NS
      
#   fi
#   ###########  
#   # create home folders
#   ###########
  
#   TENANT_USER=ad_user1
  
#   echo "Login to notebook to create home folders for \${TENANT_USER}"
    
#   kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#     exec -c app -n $TENANT_NS \$POD -- sudo su - \${TENANT_USER}
  
#   echo "Copying example files to notebook pods"
  
#   # for FILE in \$(ls -1 ./static/*)
#   # do
#   #   BASEFILE=\$(basename \$FILE)
#   #   kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#   #     cp --container app \$FILE $TENANT_NS/\$POD:/home/\${TENANT_USER}/\${BASEFILE}
      
#   #   kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#   #     exec -c app -n $TENANT_NS \$POD -- chown ad_user1:domain\\ users /home/\${TENANT_USER}/\${BASEFILE}
   
#   #   if [[ "\${BASEFILE##*.}" == ".sh" ]]; then
#   #     kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#   #       exec -c app -n $TENANT_NS \$POD -- chmod +x /home/\${TENANT_USER}/\${BASEFILE}
#   #   fi
#   # done
   
#   echo "Adding pytest and nbval python libraries for testing"
#   kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#     exec -c app -n $TENANT_NS \$POD -- sudo -E -u \${TENANT_USER} /opt/miniconda/bin/pip3 install --user --quiet --no-warn-script-location pytest nbval
#   echo "Setup HPECP CLI as admin user"
  
#   cat > ~/.hpecp_tenant.conf_tmp <<CAT_EOF
# [default]
# api_host = ${CTRL_PRV_IP}
# api_port = 8080
# use_ssl = ${INSTALL_WITH_SSL}
# verify_ssl = False
# warn_ssl = False
# username = admin
# password = admin123
# CAT_EOF
  
#   kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#     cp --container app ~/.hpecp_tenant.conf_tmp $TENANT_NS/\$POD:/home/\${TENANT_USER}/.hpecp.conf
#   kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#     exec -c app -n $TENANT_NS \$POD -- chown ad_user1:root /home/\${TENANT_USER}/.hpecp.conf
#   kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#     exec -c app -n $TENANT_NS \$POD -- chmod 600 /home/\${TENANT_USER}/.hpecp.conf
  
#   kubectl --kubeconfig <(hpecp k8scluster --id $CLUSTER_ID admin-kube-config) \
#     exec -c app -n $TENANT_NS \$POD -- sudo -E -u \${TENANT_USER} /opt/miniconda/bin/pip3 install --user --quiet --no-warn-script-location hpecp
    
# EOF1

  vars:  
    trainingcluster_yml: |-
      apiVersion: "kubedirector.hpe.com/v1beta1"
      kind: "KubeDirectorCluster"
      metadata: 
        name: "training"
        namespace: "{{ tenant_ns.stdout }}"
        labels: 
          description: ""
      spec: 
        app: "training-engine"
        namingScheme: "CrNameRole"
        appCatalog: "local"
        connections: 
          secrets: 
            - AD_USER_SECRET
            - hpecp-ext-auth-secret
        roles: 
          - 
            id: "LoadBalancer"
            members: 1
            resources: 
              requests: 
                cpu: "2"
                memory: "4Gi"
                nvidia.com/gpu: "0"
              limits: 
                cpu: "2"
                memory: "4Gi"
                nvidia.com/gpu: "0"
            #Note: "if the application is based on hadoop3 e.g. using StreamCapabilities interface, then change the below dtap label to 'hadoop3', otherwise for most applications use the default 'hadoop2'"
            podLabels: 
              hpecp.hpe.com/dtap: "hadoop2"
          - 
            id: "RESTServer"
            members: 1
            resources: 
              requests: 
                cpu: "2"
                memory: "4Gi"
                nvidia.com/gpu: "0"
              limits: 
                cpu: "2"
                memory: "4Gi"
                nvidia.com/gpu: "0"
            #Note: "if the application is based on hadoop3 e.g. using StreamCapabilities interface, then change the below dtap label to 'hadoop3', otherwise for most applications use the default 'hadoop2'"
            podLabels: 
              hpecp.hpe.com/dtap: "hadoop2"
          - 
            id: "controller"
            members: 1
            resources: 
              requests: 
                cpu: "2"
                memory: "4Gi"
                nvidia.com/gpu: "0"
              limits: 
                cpu: "2"
                memory: "4Gi"
                nvidia.com/gpu: "0"
            #Note: "if the application is based on hadoop3 e.g. using StreamCapabilities interface, then change the below dtap label to 'hadoop3', otherwise for most applications use the default 'hadoop2'"
            podLabels: 
              hpecp.hpe.com/dtap: "hadoop2"

