# Setup Data Fabric for external use

- hosts: "{{ groups['mapr'] | default([]) }}"
  tasks:

  - name: create impersonation ticket for fuse
    shell: sudo maprlogin generateticket -type servicewithimpersonation -user mapr -out /opt/mapr/conf/maprfuseticket

  - name: configure delta
    shell: pip3 install delta_spark
    # /opt/mapr/spark/spark-3.2.0/bin/pyspark --packages io.delta:delta-core_2.12:1.1.0 --conf "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension" --conf "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"

  - name: configure s3
    shell: |
      mkdir -p /home/mapr/.mc/certs/CAs
      ln -s /opt/mapr/conf/ca/chain-ca.pem /home/mapr/.mc/certs/CAs/chain-ca.pem || true
      chown -R mapr:mapr /home/mapr/.mc/certs/CAs
      export JAVA_HOME=$(dirname $(dirname $(readlink $(readlink $(which javac)))))
      ${JAVA_HOME}/bin/keytool -noprompt -importcert -file /opt/mapr/conf/ca/chain-ca.pem -alias maprca -storepass changeit -cacerts || true
    become: yes

- hosts: "{{ (groups['mapr'] | first) | default([]) }}"
  tasks:
  - name: configure spark
    shell: |
      hadoop fs -mkdir /apps/spark
      hadoop fs -chmod 777 /apps/spark
    become: yes